import streamlit as st
import boto3
import json
import uuid
import time
import os
from PIL import Image
import io
import base64

# Konfiguracja AWS
def get_aws_credentials():
    # W Å›rodowisku produkcyjnym lepiej uÅ¼ywaÄ‡ IAM roles
    return {
        'aws_access_key_id': st.secrets.get("AWS_ACCESS_KEY_ID", os.environ.get("AWS_ACCESS_KEY_ID")),
        'aws_secret_access_key': st.secrets.get("AWS_SECRET_ACCESS_KEY", os.environ.get("AWS_SECRET_ACCESS_KEY")),
        'region_name': st.secrets.get("AWS_REGION", os.environ.get("AWS_REGION", "eu-central-1"))
    }

# Inicjalizacja klientÃ³w AWS
@st.cache_resource
def init_aws_clients():
    creds = get_aws_credentials()
    s3 = boto3.client('s3', **creds)
    rekognition = boto3.client('rekognition', **creds)
    bedrock = boto3.client('bedrock-runtime', **creds)
    dynamodb = boto3.resource('dynamodb', **creds)
    
    return {
        's3': s3,
        'rekognition': rekognition,
        'bedrock': bedrock,
        'dynamodb': dynamodb
    }

# Funkcja do przesyÅ‚ania plikÃ³w do S3
def upload_to_s3(file_bytes, bucket_name):
    clients = init_aws_clients()
    s3 = clients['s3']
    
    file_key = f"uploads/{uuid.uuid4()}.jpg"
    s3.put_object(
        Bucket=bucket_name,
        Key=file_key,
        Body=file_bytes,
        ContentType='image/jpeg'
    )
    
    return file_key

# Funkcja do analizy obrazu z Amazon Rekognition
def analyze_image(bucket, file_key):
    clients = init_aws_clients()
    rekognition = clients['rekognition']
    
    # Detekcja obiektÃ³w
    detect_response = rekognition.detect_labels(
        Image={'S3Object': {'Bucket': bucket, 'Name': file_key}},
        MaxLabels=20,
        MinConfidence=70
    )
    
    # Detekcja tekstu
    text_response = rekognition.detect_text(
        Image={'S3Object': {'Bucket': bucket, 'Name': file_key}}
    )
    
    # Analiza twarzy
    face_response = rekognition.detect_faces(
        Image={'S3Object': {'Bucket': bucket, 'Name': file_key}},
        Attributes=['ALL']
    )
    
    # Kompilacja wynikÃ³w
    analysis = {
        'labels': detect_response['Labels'],
        'text': [t['DetectedText'] for t in text_response.get('TextDetections', []) if t['Type'] == 'LINE'],
        'faces': face_response.get('FaceDetails', [])
    }
    
    return analysis

# Funkcja do generowania opisu i tagÃ³w z LLM
def generate_description_and_tags(image_analysis):
    clients = init_aws_clients()
    bedrock = clients['bedrock']
    
    # Przygotowanie danych dla LLM
    detected_objects = [f"{label['Name']} (pewnoÅ›Ä‡: {label['Confidence']:.1f}%)" 
                      for label in image_analysis['labels']]
    
    detected_text = image_analysis['text']
    
    face_details = []
    for face in image_analysis['faces']:
        emotions = []
        if 'Emotions' in face:
            emotions = [e['Type'] for e in face['Emotions'] if e['Confidence'] > 50]
        
        age_range = f"{face['AgeRange']['Low']}-{face['AgeRange']['High']}"
        gender = face['Gender']['Value']
        face_details.append(f"{gender}, wiek {age_range}, emocje: {', '.join(emotions)}")
    
    # Budowanie promptu dla LLM
    prompt = f"""
    Na podstawie analizy zdjÄ™cia wykryto nastÄ™pujÄ…ce elementy:
    
    Obiekty: {', '.join(detected_objects)}
    
    {"Tekst na zdjÄ™ciu: " + ', '.join(detected_text) if detected_text else ""}
    
    {"Twarze: " + ', '.join(face_details) if face_details else ""}
    
    Na podstawie powyÅ¼szych danych, proszÄ™ wygeneruj:
    1. SzczegÃ³Å‚owy opis zdjÄ™cia (3-5 zdaÅ„)
    2. ListÄ™ 5-10 odpowiednich tagÃ³w dla tego zdjÄ™cia
    
    OdpowiedÅº sformatuj w JSON:
    {{
        "description": "Opis zdjÄ™cia...",
        "tags": ["tag1", "tag2", "tag3", ...]
    }}
    """
    
    try:
        # WywoÅ‚anie Amazon Bedrock (Claude)
        response = bedrock.invoke_model(
            modelId='anthropic.claude-3-5-sonnet-20240620-v1:0',
            body=json.dumps({
                'anthropic_version': 'bedrock-2023-05-31',
                'max_tokens': 1000,
                'temperature': 0.7,
                'messages': [{'role': 'user', 'content': prompt}]
            })
        )
        
        response_body = json.loads(response['body'].read())
        llm_output = response_body['content'][0]['text']
        
        # WyodrÄ™bnienie JSON z odpowiedzi
        start_index = llm_output.find('{')
        end_index = llm_output.rfind('}') + 1
        json_str = llm_output[start_index:end_index]
        
        # Parsowanie JSON
        result = json.loads(json_str)
        return result
    
    except Exception as e:
        st.error(f"BÅ‚Ä…d przy generowaniu opisu: {str(e)}")
        return {
            'description': 'Nie udaÅ‚o siÄ™ wygenerowaÄ‡ opisu.',
            'tags': []
        }

# Funkcja do obsÅ‚ugi pytaÅ„ FAQ
def answer_question(question):
    clients = init_aws_clients()
    bedrock = clients['bedrock']
    dynamodb = clients['dynamodb']
    
    # Generowanie embeddingu dla pytania uÅ¼ytkownika
    try:
        embed_response = bedrock.invoke_model(
            modelId='amazon.titan-embed-text-v1',
            body=json.dumps({
                'inputText': question,
                'embeddingConfig': {
                    'outputDimension': 1536
                }
            })
        )
        
        embed_body = json.loads(embed_response['body'].read())
        question_embedding = embed_body['embedding']
        
        # Przeszukanie bazy FAQ
        faq_table = dynamodb.Table('FAQ')
        all_items = faq_table.scan()['Items']
        
        # JeÅ›li baza FAQ jest pusta, uÅ¼yjemy hardcoded przykÅ‚adÃ³w do demonstracji
        if not all_items:
            example_faqs = [
                {
                    'question': 'Jak dziaÅ‚a ten asystent?',
                    'answer': 'Asystent analizuje przesÅ‚ane zdjÄ™cia uÅ¼ywajÄ…c AI, generuje opisy i tagi, oraz odpowiada na pytania z FAQ.'
                },
                {
                    'question': 'Czy moje zdjÄ™cia sÄ… przechowywane?',
                    'answer': 'ZdjÄ™cia sÄ… przechowywane w bezpieczny sposÃ³b w chmurze AWS, z kontrolÄ… dostÄ™pu.'
                },
                {
                    'question': 'Jakie rodzaje zdjÄ™Ä‡ mogÄ™ analizowaÄ‡?',
                    'answer': 'MoÅ¼esz analizowaÄ‡ rÃ³Å¼ne typy zdjÄ™Ä‡, ale system dziaÅ‚a najlepiej ze zdjÄ™ciami osÃ³b, zwierzÄ…t, krajobrazÃ³w i przedmiotÃ³w.'
                }
            ]
            
            # Symulacja embeddingÃ³w dla przykÅ‚adowych FAQ
            example_faqs_with_embeddings = []
            for faq in example_faqs:
                embed_resp = bedrock.invoke_model(
                    modelId='amazon.titan-embed-text-v1',
                    body=json.dumps({
                        'inputText': faq['question'],
                        'embeddingConfig': {
                            'outputDimension': 1536
                        }
                    })
                )
                
                embed_body = json.loads(embed_resp['body'].read())
                faq['embedding'] = embed_body['embedding']
                example_faqs_with_embeddings.append(faq)
            
            all_items = example_faqs_with_embeddings
        
        # Obliczenie podobieÅ„stwa miÄ™dzy pytaniem uÅ¼ytkownika a pytaniami z FAQ
        similarities = []
        for item in all_items:
            faq_embedding = item['embedding']
            # Obliczenie podobieÅ„stwa kosinusowego
            dot_product = sum(a * b for a, b in zip(question_embedding, faq_embedding))
            magnitude1 = sum(a * a for a in question_embedding) ** 0.5
            magnitude2 = sum(b * b for b in faq_embedding) ** 0.5
            
            if magnitude1 * magnitude2 == 0:
                similarity = 0
            else:
                similarity = dot_product / (magnitude1 * magnitude2)
            
            similarities.append({
                'question': item['question'],
                'answer': item['answer'],
                'similarity': similarity
            })
        
        # Sortowanie po podobieÅ„stwie
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        best_match = similarities[0]
        
        # JeÅ›li podobieÅ„stwo jest wystarczajÄ…co wysokie, zwracamy bezpoÅ›rednio odpowiedÅº z FAQ
        if best_match['similarity'] > 0.85:
            return {
                'matched_question': best_match['question'],
                'answer': best_match['answer'],
                'similarity': best_match['similarity']
            }
        else:
            # W przeciwnym razie, uÅ¼ywamy LLM do generowania odpowiedzi
            relevant_faqs = [f"Q: {s['question']}\nA: {s['answer']}" for s in similarities[:3]]
            context = "\n\n".join(relevant_faqs)
            
            prompt = f"""
            UÅ¼ytkownik zadaÅ‚ pytanie: "{question}"
            
            Oto najbardziej zbliÅ¼one pytania i odpowiedzi z naszego FAQ:
            
            {context}
            
            BiorÄ…c pod uwagÄ™ te informacje, udziel najlepszej moÅ¼liwej odpowiedzi na pytanie uÅ¼ytkownika.
            JeÅ›li pytanie nie jest zwiÄ…zane z dostÄ™pnymi informacjami, powiedz, Å¼e nie masz wystarczajÄ…cych danych aby odpowiedzieÄ‡.
            """
            
            llm_response = bedrock.invoke_model(
                modelId='anthropic.claude-3-5-sonnet-20240620-v1:0',
                body=json.dumps({
                    'anthropic_version': 'bedrock-2023-05-31',
                    'max_tokens': 1000,
                    'temperature': 0.7,
                    'messages': [{'role': 'user', 'content': prompt}]
                })
            )
            
            llm_body = json.loads(llm_response['body'].read())
            generated_answer = llm_body['content'][0]['text']
            
            return {
                'generated_answer': generated_answer,
                'relevant_faqs': [s['question'] for s in similarities[:3]]
            }
    
    except Exception as e:
        st.error(f"BÅ‚Ä…d przy odpowiadaniu na pytanie: {str(e)}")
        return {
            'error': f"Nie udaÅ‚o siÄ™ przetworzyÄ‡ pytania: {str(e)}"
        }

# Zapisanie danych w DynamoDB
def save_to_dynamodb(bucket, key, result):
    clients = init_aws_clients()
    dynamodb = clients['dynamodb']
    
    try:
        table = dynamodb.Table('ImageDescriptions')
        
        item = {
            'image_id': key,
            's3_bucket': bucket,
            's3_key': key,
            'description': result['description'],
            'tags': result['tags'],
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        table.put_item(Item=item)
        return True
    except Exception as e:
        st.error(f"BÅ‚Ä…d przy zapisie do DynamoDB: {str(e)}")
        return False

# GÅ‚Ã³wny interfejs Streamlit
def main():
    st.set_page_config(
        page_title="Asystent Opisywania i Tagowania ZdjÄ™Ä‡",
        page_icon="ğŸ–¼ï¸",
        layout="wide"
    )
    
    st.title("ğŸ–¼ï¸ Asystent Opisywania i Tagowania ZdjÄ™Ä‡")
    
    # Inicjalizacja stanu sesji
    if 'uploaded_image' not in st.session_state:
        st.session_state.uploaded_image = None
    if 'image_description' not in st.session_state:
        st.session_state.image_description = None
    if 'image_tags' not in st.session_state:
        st.session_state.image_tags = None
    if 'faq_answer' not in st.session_state:
        st.session_state.faq_answer = None
    
    # Tworzenie dwÃ³ch gÅ‚Ã³wnych zakÅ‚adek
    tab1, tab2 = st.tabs(["Analiza ZdjÄ™Ä‡", "FAQ"])
    
    # ZakÅ‚adka Analiza ZdjÄ™Ä‡
    with tab1:
        st.header("PrzeÅ›lij zdjÄ™cie do analizy")
        
        uploaded_file = st.file_uploader("Wybierz zdjÄ™cie...", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            # WyÅ›wietlanie przesÅ‚anego zdjÄ™cia
            image = Image.open(uploaded_file)
            st.image(image, caption="PrzesÅ‚ane zdjÄ™cie", use_column_width=True)
            st.session_state.uploaded_image = image
            
            # Przycisk do analizy
            if st.button("Analizuj zdjÄ™cie"):
                with st.spinner("AnalizujÄ™ zdjÄ™cie..."):
                    # Konwersja obrazu do bytesIO dla AWS
                    buf = io.BytesIO()
                    image.save(buf, format='JPEG')
                    image_bytes = buf.getvalue()
                    
                    # Bucket S3 - w produkcji uÅ¼yj rzeczywistego bucketa
                    bucket_name = "my-image-assistant-bucket"
                    
                    try:
                        # PrzesÅ‚anie do S3 (w trybie demonstracyjnym moÅ¼emy pominÄ…Ä‡)
                        file_key = f"demo-image-{uuid.uuid4()}.jpg"
                        
                        # JeÅ›li mamy skonfigurowany AWS, przesyÅ‚amy rzeczywiÅ›cie
                        if get_aws_credentials()['aws_access_key_id']:
                            file_key = upload_to_s3(image_bytes, bucket_name)
                            
                        # Analiza obrazu
                        image_analysis = analyze_image(bucket_name, file_key)
                        
                        # Generowanie opisu i tagÃ³w
                        result = generate_description_and_tags(image_analysis)
                        
                        # Zapis do DynamoDB (jeÅ›li mamy skonfigurowany AWS)
                        if get_aws_credentials()['aws_access_key_id']:
                            save_to_dynamodb(bucket_name, file_key, result)
                        
                        # Zapisanie wynikÃ³w w stanie sesji
                        st.session_state.image_description = result['description']
                        st.session_state.image_tags = result['tags']
                        
                    except Exception as e:
                        st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
                        
                        # Dla demonstracji, jeÅ›li AWS nie jest skonfigurowany
                        st.warning("UÅ¼ywam danych demonstracyjnych (AWS nie skonfigurowany)")
                        st.session_state.image_description = "To zdjÄ™cie przedstawia gÃ³rski krajobraz z jeziorem otoczonym przez sosnowy las. W tle widaÄ‡ oÅ›nieÅ¼one szczyty gÃ³r, a nad nimi bÅ‚Ä™kitne niebo z kilkoma pierzastymi chmurami. Na pierwszym planie widoczny jest fragment kamienistej plaÅ¼y."
                        st.session_state.image_tags = ["gÃ³ry", "jezioro", "las", "krajobraz", "natura", "niebo", "chmury", "skaÅ‚y", "odbicie", "spokÃ³j"]
            
            # WyÅ›wietlanie wynikÃ³w analizy
            if st.session_state.image_description:
                st.subheader("ğŸ“ Opis zdjÄ™cia:")
                st.write(st.session_state.image_description)
                
                st.subheader("ğŸ·ï¸ Tagi:")
                tags_html = ' '.join([f'<span style="background-color: #f0f2f6; padding: 5px 10px; border-radius: 20px; margin-right: 8px; font-size: 0.9em;">#{tag}</span>' for tag in st.session_state.image_tags])
                st.markdown(f'<div style="line-height: 2.5;">{tags_html}</div>', unsafe_allow_html=True)
    
    # ZakÅ‚adka FAQ
    with tab2:
        st.header("Zadaj pytanie dotyczÄ…ce systemu")
        
        # Pole do wprowadzania pytania
        user_question = st.text_input("Twoje pytanie:")
        
        if st.button("Zadaj pytanie") and user_question:
            with st.spinner("Szukam odpowiedzi..."):
                try:
                    answer_data = answer_question(user_question)
                    st.session_state.faq_answer = answer_data
                except Exception as e:
                    st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
                    
                    # Dla demonstracji, jeÅ›li AWS nie jest skonfigurowany
                    st.warning("UÅ¼ywam danych demonstracyjnych (AWS nie skonfigurowany)")
                    st.session_state.faq_answer = {
                        'generated_answer': "Ten asystent analizuje przesÅ‚ane zdjÄ™cia uÅ¼ywajÄ…c sztucznej inteligencji, generuje szczegÃ³Å‚owe opisy i tagi, ktÃ³re pomagajÄ… w kategoryzacji i wyszukiwaniu. PrzesÅ‚ane zdjÄ™cia sÄ… przetwarzane przez usÅ‚ugi AWS Rekognition oraz Amazon Bedrock (Claude) do analizy zawartoÅ›ci i generowania opisÃ³w naturalnym jÄ™zykiem."
                    }
        
        # WyÅ›wietlanie odpowiedzi na pytanie
        if st.session_state.faq_answer:
            st.subheader("OdpowiedÅº:")
            
            if 'matched_question' in st.session_state.faq_answer:
                st.info(f"Znaleziono podobne pytanie: \"{st.session_state.faq_answer['matched_question']}\"")
                st.write(st.session_state.faq_answer['answer'])
            elif 'generated_answer' in st.session_state.faq_answer:
                st.write(st.session_state.faq_answer['generated_answer'])
                
                if 'relevant_faqs' in st.session_state.faq_answer and st.session_state.faq_answer['relevant_faqs']:
                    st.subheader("PowiÄ…zane pytania z FAQ:")
                    for q in st.session_state.faq_answer['relevant_faqs']:
                        st.markdown(f"- {q}")
    
    # Stopka
    st.markdown("---")
    st.markdown("ğŸ“Š Asystent opisywania i tagowania zdjÄ™Ä‡ | Projekt rekrutacyjny")

if __name__ == "__main__":
    main()