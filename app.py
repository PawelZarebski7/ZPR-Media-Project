import streamlit as st
import boto3
import json
import uuid
import time
import os
from PIL import Image
import io
import base64

# Konfiguracja AWS
def get_aws_credentials():
    # Odczytanie danych z secrets.toml - nowa struktura
    return {
        'aws_access_key_id': st.secrets["aws"]["AWS_ACCESS_KEY_ID"],
        'aws_secret_access_key': st.secrets["aws"]["AWS_SECRET_ACCESS_KEY"],
        'region_name': st.secrets["aws"]["AWS_REGION"]
    }

# Inicjalizacja klientÃ³w AWS
@st.cache_resource
def init_aws_clients():
    creds = get_aws_credentials()
    s3 = boto3.client('s3', **creds)
    rekognition = boto3.client('rekognition', **creds)
    bedrock = boto3.client('bedrock-runtime', **creds)
    dynamodb = boto3.resource('dynamodb', **creds)
    
    return {
        's3': s3,
        'rekognition': rekognition,
        'bedrock': bedrock,
        'dynamodb': dynamodb
    }

# Funkcja do przesyÅ‚ania plikÃ³w do S3
def upload_to_s3(file_bytes, bucket_name):
    clients = init_aws_clients()
    s3 = clients['s3']
    
    file_key = f"uploads/{uuid.uuid4()}.jpg"
    s3.put_object(
        Bucket=bucket_name,
        Key=file_key,
        Body=file_bytes,
        ContentType='image/jpeg'
    )
    
    return file_key

# Funkcja do analizy obrazu z Amazon Rekognition
def analyze_image(bucket, file_key):
    clients = init_aws_clients()
    rekognition = clients['rekognition']
    
    # Detekcja obiektÃ³w
    detect_response = rekognition.detect_labels(
        Image={'S3Object': {'Bucket': bucket, 'Name': file_key}},
        MaxLabels=20,
        MinConfidence=70
    )
    
    # Detekcja tekstu
    text_response = rekognition.detect_text(
        Image={'S3Object': {'Bucket': bucket, 'Name': file_key}}
    )
    
    # Analiza twarzy
    face_response = rekognition.detect_faces(
        Image={'S3Object': {'Bucket': bucket, 'Name': file_key}},
        Attributes=['ALL']
    )
    
    # Kompilacja wynikÃ³w
    analysis = {
        'labels': detect_response['Labels'],
        'text': [t['DetectedText'] for t in text_response.get('TextDetections', []) if t['Type'] == 'LINE'],
        'faces': face_response.get('FaceDetails', [])
    }
    
    return analysis

# Funkcja do generowania opisu i tagÃ³w z LLM
def generate_description_and_tags(image_analysis):
    clients = init_aws_clients()
    bedrock = clients['bedrock']
    
    # Przygotowanie danych dla LLM
    detected_objects = [f"{label['Name']} (pewnoÅ›Ä‡: {label['Confidence']:.1f}%)" 
                      for label in image_analysis['labels']]
    
    detected_text = image_analysis['text']
    
    face_details = []
    for face in image_analysis['faces']:
        emotions = []
        if 'Emotions' in face:
            emotions = [e['Type'] for e in face['Emotions'] if e['Confidence'] > 50]
        
        age_range = f"{face['AgeRange']['Low']}-{face['AgeRange']['High']}"
        gender = face['Gender']['Value']
        face_details.append(f"{gender}, wiek {age_range}, emocje: {', '.join(emotions)}")
    
    # Budowanie promptu dla LLM
    prompt = f"""
    Na podstawie analizy zdjÄ™cia wykryto nastÄ™pujÄ…ce elementy:
    
    Obiekty: {', '.join(detected_objects)}
    
    {"Tekst na zdjÄ™ciu: " + ', '.join(detected_text) if detected_text else ""}
    
    {"Twarze: " + ', '.join(face_details) if face_details else ""}
    
    Na podstawie powyÅ¼szych danych, proszÄ™ wygeneruj:
    1. SzczegÃ³Å‚owy opis zdjÄ™cia (3-5 zdaÅ„)
    2. ListÄ™ 5-10 odpowiednich tagÃ³w dla tego zdjÄ™cia
    
    OdpowiedÅº sformatuj w JSON:
    {{
        "description": "Opis zdjÄ™cia...",
        "tags": ["tag1", "tag2", "tag3", ...]
    }}
    """
    
    try:
        # WywoÅ‚anie Amazon Bedrock (Claude) - zaktualizowane ID profilu inferencyjnego
        response = bedrock.invoke_model(
            modelId='eu.anthropic.claude-3-7-sonnet-20250219-v1:0',  # Profil inferencyjny Claude 3.7 Sonnet
            body=json.dumps({
                'anthropic_version': 'bedrock-2023-05-31',
                'max_tokens': 1000,
                'temperature': 0.7,
                'messages': [{'role': 'user', 'content': prompt}]
            })
        )
        
        response_body = json.loads(response['body'].read())
        llm_output = response_body['content'][0]['text']
        
        # WyodrÄ™bnienie JSON z odpowiedzi
        start_index = llm_output.find('{')
        end_index = llm_output.rfind('}') + 1
        json_str = llm_output[start_index:end_index]
        
        # Parsowanie JSON
        result = json.loads(json_str)
        return result
    
    except Exception as e:
        st.error(f"BÅ‚Ä…d przy generowaniu opisu: {str(e)}")
        return {
            'description': 'Nie udaÅ‚o siÄ™ wygenerowaÄ‡ opisu.',
            'tags': []
        }

# Uproszona funkcja do obsÅ‚ugi pytaÅ„ FAQ bez uÅ¼ycia embeddings
def answer_question(question):
    # PrzykÅ‚adowe FAQ
    example_faqs = [
        {
            'question': 'Jak dziaÅ‚a ten asystent?',
            'answer': 'Asystent analizuje przesÅ‚ane zdjÄ™cia uÅ¼ywajÄ…c AI, generuje opisy i tagi, oraz odpowiada na pytania z FAQ.'
        },
        {
            'question': 'Czy moje zdjÄ™cia sÄ… przechowywane?',
            'answer': 'ZdjÄ™cia sÄ… przechowywane w bezpieczny sposÃ³b w chmurze AWS, z kontrolÄ… dostÄ™pu.'
        },
        {
            'question': 'Jakie rodzaje zdjÄ™Ä‡ mogÄ™ analizowaÄ‡?',
            'answer': 'MoÅ¼esz analizowaÄ‡ rÃ³Å¼ne typy zdjÄ™Ä‡, ale system dziaÅ‚a najlepiej ze zdjÄ™ciami osÃ³b, zwierzÄ…t, krajobrazÃ³w i przedmiotÃ³w.'
        }
    ]
    
    # Znalezienie najbardziej podobnego pytania
    best_match = None
    highest_score = 0
    
    for faq in example_faqs:
        # Proste porÃ³wnanie sÅ‚Ã³w
        faq_words = set(faq['question'].lower().split())
        question_words = set(question.lower().split())
        common_words = faq_words.intersection(question_words)
        
        if len(faq_words) > 0:
            score = len(common_words) / len(faq_words)
            if score > highest_score:
                highest_score = score
                best_match = faq
    
    if highest_score > 0.5:  # PrÃ³g podobieÅ„stwa
        return {
            'matched_question': best_match['question'],
            'answer': best_match['answer'],
            'similarity': highest_score
        }
    else:
        # Generowanie odpowiedzi za pomocÄ… Claude
        clients = init_aws_clients()
        bedrock = clients['bedrock']
        
        prompt = f"""
        UÅ¼ytkownik zadaÅ‚ pytanie: "{question}"
        
        Oto pytania i odpowiedzi z naszego FAQ:
        
        Q: Jak dziaÅ‚a ten asystent?
        A: Asystent analizuje przesÅ‚ane zdjÄ™cia uÅ¼ywajÄ…c AI, generuje opisy i tagi, oraz odpowiada na pytania z FAQ.
        
        Q: Czy moje zdjÄ™cia sÄ… przechowywane?
        A: ZdjÄ™cia sÄ… przechowywane w bezpieczny sposÃ³b w chmurze AWS, z kontrolÄ… dostÄ™pu.
        
        Q: Jakie rodzaje zdjÄ™Ä‡ mogÄ™ analizowaÄ‡?
        A: MoÅ¼esz analizowaÄ‡ rÃ³Å¼ne typy zdjÄ™Ä‡, ale system dziaÅ‚a najlepiej ze zdjÄ™ciami osÃ³b, zwierzÄ…t, krajobrazÃ³w i przedmiotÃ³w.
        
        BiorÄ…c pod uwagÄ™ te informacje, udziel najlepszej moÅ¼liwej odpowiedzi na pytanie uÅ¼ytkownika.
        JeÅ›li pytanie nie jest zwiÄ…zane z dostÄ™pnymi informacjami, powiedz, Å¼e nie masz wystarczajÄ…cych danych aby odpowiedzieÄ‡.
        """
        
        try:
            llm_response = bedrock.invoke_model(
                modelId='eu.anthropic.claude-3-7-sonnet-20250219-v1:0',
                body=json.dumps({
                    'anthropic_version': 'bedrock-2023-05-31',
                    'max_tokens': 1000,
                    'temperature': 0.7,
                    'messages': [{'role': 'user', 'content': prompt}]
                })
            )
            
            llm_body = json.loads(llm_response['body'].read())
            generated_answer = llm_body['content'][0]['text']
            
            return {
                'generated_answer': generated_answer,
                'relevant_faqs': [faq['question'] for faq in example_faqs]
            }
        except Exception as e:
            st.error(f"BÅ‚Ä…d przy generowaniu odpowiedzi: {str(e)}")
            return {
                'error': f"Nie udaÅ‚o siÄ™ przetworzyÄ‡ pytania: {str(e)}"
            }

# Zapisanie danych w DynamoDB
def save_to_dynamodb(bucket, key, result):
    clients = init_aws_clients()
    dynamodb = clients['dynamodb']
    
    try:
        table = dynamodb.Table('ImageDescriptions')
        
        # SprawdÅº czy tabela istnieje
        try:
            table.table_status
        except Exception as e:
            st.warning(f"Problem z tabelÄ… DynamoDB: {str(e)}")
            return False
            
        item = {
            'image_id': key,
            's3_bucket': bucket,
            's3_key': key,
            'description': result['description'],
            'tags': result['tags'],
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        table.put_item(Item=item)
        return True
    except Exception as e:
        st.error(f"BÅ‚Ä…d przy zapisie do DynamoDB: {str(e)}")
        return False

# GÅ‚Ã³wny interfejs Streamlit
def main():
    st.set_page_config(
        page_title="Asystent Opisywania i Tagowania ZdjÄ™Ä‡",
        page_icon="ğŸ–¼ï¸",
        layout="wide"
    )
    
    st.title("ğŸ–¼ï¸ Asystent Opisywania i Tagowania ZdjÄ™Ä‡")
    
    # Inicjalizacja stanu sesji
    if 'uploaded_image' not in st.session_state:
        st.session_state.uploaded_image = None
    if 'image_description' not in st.session_state:
        st.session_state.image_description = None
    if 'image_tags' not in st.session_state:
        st.session_state.image_tags = None
    if 'faq_answer' not in st.session_state:
        st.session_state.faq_answer = None
    
    # Tworzenie dwÃ³ch gÅ‚Ã³wnych zakÅ‚adek
    tab1, tab2 = st.tabs(["Analiza ZdjÄ™Ä‡", "FAQ"])
    
    # ZakÅ‚adka Analiza ZdjÄ™Ä‡
    with tab1:
        st.header("PrzeÅ›lij zdjÄ™cie do analizy")
        
        uploaded_file = st.file_uploader("Wybierz zdjÄ™cie...", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            # WyÅ›wietlanie przesÅ‚anego zdjÄ™cia
            image = Image.open(uploaded_file)
            st.image(image, caption="PrzesÅ‚ane zdjÄ™cie", use_container_width=True)
            st.session_state.uploaded_image = image
            
            # Przycisk do analizy
            if st.button("Analizuj zdjÄ™cie"):
                with st.spinner("AnalizujÄ™ zdjÄ™cie..."):
                    # Konwersja obrazu do bytesIO dla AWS
                    buf = io.BytesIO()
                    
                    # Konwersja obrazu z RGBA do RGB, jeÅ›li jest to konieczne
                    if image.mode == 'RGBA':
                        image = image.convert('RGB')
                    
                    image.save(buf, format='JPEG')
                    image_bytes = buf.getvalue()
                    
                    # Bucket S3 - pobierz z konfiguracji
                    bucket_name = st.secrets["aws"]["S3_BUCKET_NAME"]
                    
                    try:
                        # PrzesÅ‚anie do S3
                        file_key = upload_to_s3(image_bytes, bucket_name)
                            
                        # Analiza obrazu
                        image_analysis = analyze_image(bucket_name, file_key)
                        
                        # Generowanie opisu i tagÃ³w
                        result = generate_description_and_tags(image_analysis)
                        
                        # Zapis do DynamoDB
                        save_to_dynamodb(bucket_name, file_key, result)
                        
                        # Zapisanie wynikÃ³w w stanie sesji
                        st.session_state.image_description = result['description']
                        st.session_state.image_tags = result['tags']
                        
                    except Exception as e:
                        st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
            
            # WyÅ›wietlanie wynikÃ³w analizy
            if st.session_state.image_description:
                st.subheader("ğŸ“ Opis zdjÄ™cia:")
                st.write(st.session_state.image_description)
                
                st.subheader("ğŸ·ï¸ Tagi:")
                tags_html = ' '.join([f'<span style="background-color: #f0f2f6; padding: 5px 10px; border-radius: 20px; margin-right: 8px; font-size: 0.9em;">#{tag}</span>' for tag in st.session_state.image_tags])
                st.markdown(f'<div style="line-height: 2.5;">{tags_html}</div>', unsafe_allow_html=True)
    
    # ZakÅ‚adka FAQ
    with tab2:
        st.header("Zadaj pytanie dotyczÄ…ce systemu")
        
        # Pole do wprowadzania pytania
        user_question = st.text_input("Twoje pytanie:")
        
        if st.button("Zadaj pytanie") and user_question:
            with st.spinner("Szukam odpowiedzi..."):
                try:
                    answer_data = answer_question(user_question)
                    st.session_state.faq_answer = answer_data
                except Exception as e:
                    st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
        
        # WyÅ›wietlanie odpowiedzi na pytanie
        if st.session_state.faq_answer:
            st.subheader("OdpowiedÅº:")
            
            if 'matched_question' in st.session_state.faq_answer:
                st.info(f"Znaleziono podobne pytanie: \"{st.session_state.faq_answer['matched_question']}\"")
                st.write(st.session_state.faq_answer['answer'])
            elif 'generated_answer' in st.session_state.faq_answer:
                st.write(st.session_state.faq_answer['generated_answer'])
                
                if 'relevant_faqs' in st.session_state.faq_answer and st.session_state.faq_answer['relevant_faqs']:
                    st.subheader("PowiÄ…zane pytania z FAQ:")
                    for q in st.session_state.faq_answer['relevant_faqs']:
                        st.markdown(f"- {q}")
    
    # Stopka
    st.markdown("---")
    st.markdown("ğŸ“Š Asystent opisywania i tagowania zdjÄ™Ä‡ | Projekt rekrutacyjny")

if __name__ == "__main__":
    main()